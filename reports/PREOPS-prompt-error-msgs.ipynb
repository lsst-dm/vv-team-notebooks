{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3669b84-3ad7-4aea-be85-92bb46d8d914",
   "metadata": {},
   "source": [
    "Pipeline Errors for night of {{ params.day_obs }}\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f415fb2-9873-41a5-8735-0596517e8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_obs = \"2025-05-01\"\n",
    "instrument = \"LSSTCam\"\n",
    "survey = \"BLOCK-365\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbade4-2b57-48f9-950d-7124b4e810fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!eups list lsst_distrib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bd45b-14d0-4578-b9cd-3bf432c6c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $IMAGE_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce894e-7a5b-44fa-9163-fe4ef6366bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "butler_alias = \"/repo/embargo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678de1f-cdc5-4842-941d-b03f0f06630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import lsst.daf.butler as dafButler\n",
    "from lsst.daf.butler import DimensionNameError\n",
    "from lsst.pipe.base import Pipeline\n",
    "import tabulate\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "@dataclass\n",
    "class error_summary:\n",
    "    visit: int\n",
    "    detector: int\n",
    "    error_messages: list\n",
    "\n",
    "b = dafButler.Butler(butler_alias, collections=f\"{instrument}/prompt/output-{day_obs:s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f97f97-b7b2-4e78-9ab8-893d778dcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposures = [e.id for e in b.query_dimension_records(\n",
    "        \"exposure\", where=f\"exposure.instrument='{instrument}' AND exposure.science_program='{survey}' AND exposure.day_obs={day_obs.replace(\"-\", \"\")}\", explain=False)]\n",
    "visits = [v.id for v in b.query_dimension_records(\n",
    "        \"visit\", where=f\"visit.instrument='{instrument}' AND visit.science_program='{survey}' AND visit.day_obs={day_obs.replace(\"-\", \"\")}\", explain=False)]\n",
    "\n",
    "print(f\"Number of unique exposure ids: {len(set(exposures))}\")\n",
    "print(f\"Number of unique visit ids: {len(set(visits))}\")\n",
    "\n",
    "print(f\"Exposures not in visit list: {set(exposures) - set(visits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
        "# Cache butler queries which get used multiple times\n",
    "query_cache = {}\n",
    "def cached_query(dataset_type, where):\n",
    "    key = (dataset_type, where)\n",
    "    if key not in query_cache:\n",
    "        query_cache[key] = set(\n",
    "            (x.dataId.get('visit') or x.dataId.get('exposure'), x.dataId['detector'])\n",
    "            for x in b.query_datasets(dataset_type, where=where, limit=None, explain=False)\n",
    "        )\n",
    "    else:\n",
    "        print(\"We used this function\")\n",
    "    return query_cache[key]\n",
    "\n",
    "log_visit_detector = set([(x.dataId['visit'], x.dataId['detector']) for x in b.query_datasets(\n",
    "    \"calibrateImage_log\", where=f\"exposure.science_program='{survey}' AND instrument='{instrument}'\", limit=None, explain=False\n",
    ")])\n",
    "\n",
    "# Query for number of records\n",
    "\n",
    "log_exposure_detector = cached_query(\"isr_log\", f\"exposure.science_program='{survey}' AND instrument='{instrument}'\")\n",
    "log_visit_detector = cached_query(\"calibrateImage_log\", f\"visit.science_program='{survey}' AND instrument='{instrument}'\")\n",
    "isr_exposure_detector = cached_query(\"post_isr_image\", f\"exposure.science_program='{survey}' AND instrument='{instrument}'\")\n",
    "pvi_visit_detector = cached_query(\"initial_photometry_match_detector\", f\"visit.science_program='{survey}' AND instrument='{instrument}'\")\n",
    "dia_visit_detector = cached_query(\"apdb_marker\", f\"visit.science_program='{survey}' AND instrument='{instrument}'\")\n",
    "\n",
    "missing_pvis = log_visit_detector - pvi_visit_detector\n",
    "missing_visits = [x[0] for x in missing_pvis]\n",
    "\n",
    "print(f\"Number of ISR records in butler: {len(log_exposure_detector)}\")\n",
    "print(f\"Number of calibrateImage records in butler: {len(log_visit_detector)}\")\n",
    "print(f\"Number of successful ISR results: {len(isr_exposure_detector)}\")\n",
    "print(f\"Number of successful processCcd results: {len(pvi_visit_detector)}\")\n",
    "print(f\"Number of unsuccessful processCcd attempts: {len(missing_pvis)}\")\n",
    "print(f\"Number of successful DIA attempts: {len(dia_visit_detector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f001bc-3a06-4cd0-a2f5-6135900c30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_error_summaries(log_dataset_types_exposure, log_dataset_types_visit, data_ids):\n",
    "    error_summaries = []\n",
    "    for visit, detector in data_ids:\n",
    "    \n",
    "        visit_errors = []\n",
    "        \n",
    "        for ds_types in log_dataset_types_exposure:\n",
    "            log_messages = b.get(ds_types, dataId={\"instrument\": instrument, \"exposure\": visit, \"detector\": detector})\n",
    "            isr_errors = [msg for msg in log_messages if msg.levelno > 30]\n",
    "            visit_errors.extend(isr_errors)\n",
    "        \n",
    "        for ds_types in log_dataset_types_visit:\n",
    "            try:\n",
    "                log_messages = b.get(ds_types, dataId={\"instrument\": instrument, \"visit\": visit, \"detector\": detector})\n",
    "            except DimensionNameError: # Visit records can be missing due to corrupted headers.\n",
    "                errors = []\n",
    "            else:\n",
    "                errors = [msg for msg in log_messages if msg.levelno > 30 or \"SIGTERM\" in msg.message]\n",
    "            finally:\n",
    "                visit_errors.extend(errors)\n",
    "    \n",
    "        error_summaries.append(error_summary(visit=visit, detector=detector, error_messages=visit_errors))\n",
    "    return error_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976bb71-4f42-43a5-bb48-ebaa116b617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url_from_visit(visit):\n",
    "    s = str(visit)\n",
    "    day_string = f\"{s[0:4]}-{s[4:6]}-{s[6:8]}\"\n",
    "    counter = int(s[8:])\n",
    "    if instrument == \"LATISS\":\n",
    "        # Example: https://usdf-rsp.slac.stanford.edu/rubintv/summit-usdf/auxtel/event?key=auxtel/2024-08-12/monitor/000351/auxtel_monitor_2024-08-12_000351.png\n",
    "        url = f\"https://usdf-rsp.slac.stanford.edu/rubintv/summit-usdf/auxtel/event?key=auxtel/{day_string}/monitor/{counter:06d}/auxtel_monitor_{day_string}_{counter:06d}.png\"\n",
    "    elif instrument == \"LSSTComCam\":\n",
    "        short_name = \"comcam\"\n",
    "        # Example: https://usdf-rsp.slac.stanford.edu/rubintv/summit-usdf/comcam/event?key=comcam/2024-11-23/focal_plane_mosaic/000336/comcam_focal_plane_mosaic_2024-11-23_000336.jpg\n",
    "        url = f\"https://usdf-rsp.slac.stanford.edu/rubintv/summit-usdf/{short_name}/event?key={short_name}/{day_string}/focal_plane_mosaic/{counter:06d}/{short_name}_focal_plane_mosaic_{day_string}_{counter:06d}.jpg\"\n",
    "    elif instrument == \"LSSTCam\":\n",
    "        short_name = \"lsstcam\"\n",
    "        url = f\"https://usdf-rsp.slac.stanford.edu/rubintv/summit-usdf/{short_name}/event?key={short_name}/{day_string}/focal_plane_mosaic/{counter:06d}/{short_name}_focal_plane_mosaic_{day_string}_{counter:06d}.jpg\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d2f33-8db0-457b-8d74-7609b216ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_uri(f\"$AP_PIPE_DIR/pipelines/{instrument}/ApPipe.yaml#prompt\")\n",
    "pipeline.addConfigOverride(\"associateApdb\", \"apdb_config_url\", \"dummy\")\n",
    "\n",
    "pipeline_graph = pipeline.to_graph(registry=b.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6aa751-0818-472e-bb9c-e3adcf969940",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_errors = {\n",
    "    \"Exception BadAstrometryFit: Poor quality astrometric fit\",\n",
    "    \"Exception NonfinitePsfShapeError: Failed to determine PSF\",\n",
    "    \"Exception NormalizedCalibrationFluxError\",\n",
    "    \"Exception MeasureApCorrError: Unable to measure aperture correction\",\n",
    "    \"Exception ObjectSizeNoGoodSourcesError\",\n",
    "    \"MatcherFailure: No matches found\",\n",
    "    \"MatcherFailure: Not enough catalog objects\",\n",
    "    \"MatcherFailure: Not enough refcat objects\",\n",
    "    \"MatcherFailure: No matches to use for photocal\",\n",
    "    \"NoPsfStarsToStarsMatchError\",\n",
    "    \"PsfexTooFewGoodStarsError\",\n",
    "    \"RuntimeError: Cannot compute PSF matching kernel: too few sources selected\",\n",
    "    \"RuntimeError: No good PSF candidates to pass to PSFEx\",\n",
    "    \"PsfexNoGoodStarsError\",\n",
    "    \"RuntimeError: No objects passed our cuts for consideration as psf stars\",\n",
    "    \"SIGTERM\",\n",
    "    \"ValueError: cannot convert float NaN to integer\",\n",
    "    \"Exception AllCentroidsFlaggedError\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1cabe-4710-4c1d-aee9-b624f7d17c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_records = log_exposure_detector\n",
    "table_contents = []\n",
    "last_task = \"isr\"\n",
    "for task in itertools.chain(pipeline_graph.tasks, [\"end\"]):\n",
    "    if task in (\"isr\", \"getRegionTimeFromVisit\"):\n",
    "        continue\n",
    "    if task != \"end\":\n",
    "        records = set([(x.dataId['visit'], x.dataId['detector']) for x in b.query_datasets(\n",
    "            task+\"_log\", where=f\"visit.science_program='{survey}'AND instrument='{instrument}'\", limit=None, explain=False\n",
    "        )])\n",
    "        error_summaries = make_error_summaries([\"isr_log\"], [last_task+\"_log\"], last_records - records)\n",
    "        print(f\"  {len(records):d} {task} records\")\n",
    "    else:\n",
    "        error_summaries = make_error_summaries([\"isr_log\"], [last_task+\"_log\"], last_records - dia_visit_detector)\n",
    "    \n",
    "    for e in error_summaries: \n",
    "        if e.error_messages:\n",
    "            msg = e.error_messages[-1].message[:1000]\n",
    "        # Ignore those that did not run rewarpTemplate; likely single frame only.\n",
    "        elif task == \"rewarpTemplate\":\n",
    "            continue\n",
    "        elif task == \"end\":\n",
    "            msg = \"?\"\n",
    "        else:\n",
    "            msg = \"\"\n",
    "        table_contents.append((e.visit, e.detector, make_url_from_visit(e.visit), last_task, msg)) \n",
    "        \n",
    "    last_task = task\n",
    "    last_records = records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290bff7-01ab-4b7f-b0ed-149fe9873c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(table_contents):d} errors, not including those falling back from ApPipe to SingleFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d247c-8f13-49f6-80f8-3205d9486acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(sorted(table_contents), columns=(\"Visit\", \"Det\", \"Img\", \"Last Task\", \"Error Message\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebf509-30ea-4ebb-a2db-6247d8b38b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows containing any of the substrings\n",
    "if table.empty:\n",
    "    print(\"There were no pipeline errors\")\n",
    "else:\n",
    "    mask = table['Error Message'].apply(lambda x: any(err.lower() in x.lower() for err in recurrent_errors) if pd.notnull(x) else False)\n",
    "\n",
    "    # Filter the DataFrame to show matching rows\n",
    "    known_errs = table[mask]\n",
    "    \n",
    "    # Count occurrences of each substring\n",
    "    error_counts = {err: known_errs['Error Message'].str.contains(err, case=False, na=False, regex=False).sum() for err in recurrent_errors}\n",
    "    \n",
    "    for err, counts in error_counts.items():\n",
    "        if counts != 0:\n",
    "            print(f\"- {counts} {err}\")\n",
    "    \n",
    "    print(\"Matching rows:\")\n",
    "    display(known_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdac024-f9b7-4d23-9962-8776bafe6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "if table.empty:\n",
    "    pass\n",
    "else:\n",
    "    other_errs = table[~mask]\n",
    "    other_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_errs.to_csv(f\"known_errors_{day_obs}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_errs.to_csv(f\"new_errors_{day_obs}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
